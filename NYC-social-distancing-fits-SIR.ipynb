{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC data & social distancing fits (SIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook compares the SIR model fits of the NYC data with or without implemented social distancing measures. \n",
    "\n",
    "**TL;DR:** \n",
    "\n",
    "1. The data is described best if a social distancing measures are in place.\n",
    "2. Precise knowledge about new admissions is more important than knowledge about new infections assuming a 15% relative uncertainty in new admissions and a 50% or larger uncertainty in new known cases.\n",
    "3. To reliably run social distancing fits, a \"bend\" in the data (deviation from exponential growth) should be visible.\n",
    "4. Once the bend is visible, predictions are consistent and fit precision seems limited by data. Predictions in the range of a week seem feasible, after that, the extrapolation uncertainty becomes large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "from datetime import date, timedelta\n",
    "\n",
    "from pandas import DataFrame, date_range, Series\n",
    "from numpy import array, linspace, log, sqrt, exp, arange\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from gvar import gvar, mean, sdev\n",
    "from lsqfit import nonlinear_fit\n",
    "\n",
    "from models import sir_step, one_minus_logistic_fcn, FitFcn\n",
    "from utils.prepare_df import prepare_case_hosp_death, COMMIT_HASH_LAST\n",
    "from utils.plotting import COLUMN_NAME_MAP, plot_fits, summarize_fit, plot_fit_range\n",
    "\n",
    "print(COMMIT_HASH_LAST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BIN_SIZE = 2\n",
    "# See also the NYC-data-preparation notebook for choice analysis\n",
    "\n",
    "chd_df = prepare_case_hosp_death(\n",
    "    COMMIT_HASH_LAST,  # Specify NYC repo commit hash to ensure same data\n",
    "    bin_day_range=BIN_SIZE,  # How many days should be grouped as one\n",
    "    drop_days_end=3,  # Drop rows where date awas 3 days within reporting\n",
    ").loc[\n",
    "    \"2020-03-08\":\"2020-04-01\"\n",
    "]  # Only consider given time range\n",
    "chd_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit the SIR model, I distinguish between two sets of parameters:\n",
    "\n",
    "1. Fit data stored in a `XX` and `YY` variable. This data does not change after being specified once.\n",
    "2. Fit parameters stored in a prior which specifies the initial belive. These parameters are optimized while fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is data considerd fix in fit\n",
    "XX = {\n",
    "    \"initial_susceptible\": int(8.6e6),  # https://en.wikipedia.org/wiki/New_York_City\n",
    "    \"initial_hospitalized\": chd_df.hospitalized_cummulative.iloc[0],\n",
    "    \"initial_recovered\": 0,\n",
    "    \"n_iter\": chd_df.shape[0] + 1,  # Because of the bin size, one iteration = 3 days\n",
    "    \"bin_size\": BIN_SIZE,  # To convert units later on\n",
    "}\n",
    "print(XX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this fit to work, the `YY` variable must also quantify uncertainty.\n",
    "I believe that daily new admissions to a hospital (`hospitalized_new`) are more accurate than a count of daily new infections (`infected_new`, I have no estimation about how accurate the estimation of new infections is at all). Thus I emphasize `hospitalized_new` over `infected_new`.\n",
    "In this context, the $\\chi^2$ per d.o.f. is not necessarily meaningful and uncertainties rather quantify relative weights if how much you trust individual data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infected_new = chd_df[\"infected_new\"].values\n",
    "hospitalized_new = chd_df[\"hospitalized_new\"].values\n",
    "\n",
    "# This assumes that there is a 50% uncertainty in the number of infected people\n",
    "## And at least 300 (if the number is small to not emphasize early measurments too much)\n",
    "delta_infected_new = [max(300, infected * 0.5) for infected in infected_new]\n",
    "\n",
    "# This assumes that there is a 10% uncertainty in the number of hospitalized people with a minimum of 50\n",
    "delta_hospitalized_new = [hospitalized * 0.15 for hospitalized in hospitalized_new]\n",
    "\n",
    "YY = gvar(\n",
    "    [infected_new, hospitalized_new], [delta_infected_new, delta_hospitalized_new]\n",
    ").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About doubling time and social distancing**\n",
    "\n",
    "If one assumes, in the initial phase of the COVID-19 spread, $S(t) \\approx S_0$, one has\n",
    "\n",
    "$$\n",
    "    \\dot I(t) = (\\beta_I S_0 - \\gamma_I) I(t)\n",
    "    \\quad \\Rightarrow \\quad\n",
    "    I(t) = I_0 \\exp\\{(\\beta_I S_0 - \\gamma_I)t\\}\n",
    "$$\n",
    "\n",
    "Thus, the initial doubling time is defined as\n",
    "\n",
    "$$\n",
    "    I(t_2) = 2 I_0 = I_0 \\exp\\{(\\beta_I S_0 - \\gamma_I)t_2\\} \n",
    "    \\quad \\Rightarrow \\quad \n",
    "    t_2 = \\frac{\\ln(2)}{\\beta_I S_0 - \\gamma_I}\n",
    "    \\quad \\Rightarrow \\quad \n",
    "    \\beta_I =  \\frac{1}{S_0} \\left[ \\frac{\\ln(2)}{t_2} +  \\gamma_I \\right]\n",
    "$$\n",
    "\n",
    "In later fits, social distancing policies are introduced. \n",
    "Thus, the growth rate $\\beta_I$ becomes a function of time which is implemented by a logistic function with three unknown coefficients\n",
    "\n",
    "$$\n",
    "    \\beta_I(t; R, t_0, \\Delta t) = \\beta_I \\left[ 1 - \\frac{R}{1+\\exp\\{-(t-t_0)\\Delta t\\}}\\right]\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular SIR, no social distancing policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the fit function\n",
    "fcn = FitFcn(\n",
    "    sir_step,  # run regular SIR model\n",
    "    columns=[\n",
    "        \"infected_new\",\n",
    "        \"hospitalized_new\",\n",
    "    ],  # return only data for these two columns\n",
    "    as_array=True,  # return array not df\n",
    "    drop_rows=[0],  # drop first row (since new values are NaN in this row)\n",
    ")\n",
    "\n",
    "# And the prior estimates of fit parameters\n",
    "## gvars are gaussian random numbers described by their mean and standard deviation\n",
    "prior = {\n",
    "    # 5(2) days is the estimated initial doubling time\n",
    "    \"inital_doubling_time\": gvar(5, 2),\n",
    "    # Days until one is recovered\n",
    "    \"recovery_days_i\": gvar(14, 5),\n",
    "    # Wild guess of how many where initially infected\n",
    "    \"initial_infected\": gvar(1.0e4, 2.0e4),\n",
    "    # Rate of infected people becoming hospitalized\n",
    "    \"hospitalization_rate\": gvar(0.3, 0.5),\n",
    "}\n",
    "\n",
    "# Run the fit\n",
    "fit = nonlinear_fit(data=(XX, YY), fcn=fcn, prior=prior)\n",
    "\n",
    "# And present it\n",
    "summarize_fit(fit)\n",
    "fig = plot_fits(fit, x=chd_df.index[1:])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular SIR, with social distancing policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit function now with beta_i_fcn\n",
    "fcn_w_distancing = FitFcn(\n",
    "    sir_step,\n",
    "    columns=[\"infected_new\", \"hospitalized_new\"],\n",
    "    beta_i_fcn=one_minus_logistic_fcn,\n",
    "    as_array=True,\n",
    "    drop_rows=[0],\n",
    ")\n",
    "\n",
    "# Copy prior from before but add social distancing parameters\n",
    "prior_w_distancing = prior.copy()\n",
    "# Maximal reduction of social distancing: R\n",
    "prior_w_distancing[\"ratio\"] = gvar(0.7, 0.3)\n",
    "# How many days to go from ~ r to 0.5r: Delta t\n",
    "prior_w_distancing[\"social_distance_halfing_days\"] = gvar(14, 7)\n",
    "# After how many days the measures hits 0.5r: t0\n",
    "prior_w_distancing[\"social_distance_delay\"] = gvar(14, 7)\n",
    "\n",
    "# Run the fit\n",
    "fit_w_distancing = nonlinear_fit(\n",
    "    data=(XX, YY), fcn=fcn_w_distancing, prior=prior_w_distancing\n",
    ")\n",
    "\n",
    "# Summarize the fit\n",
    "summarize_fit(fit_w_distancing)\n",
    "fig = plot_fits(fit_w_distancing, x=chd_df.index[1:])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular SIR, with social distancing policies, larger infected uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is likely that the number of known cases (infections) is significantly underestimated.\n",
    "How does the fit change if we blow up the uncertainty of `infected_new` by 300% of it's mean value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infected_new = chd_df[\"infected_new\"].values\n",
    "hospitalized_new = chd_df[\"hospitalized_new\"].values\n",
    "\n",
    "# This assumes that there is a 300% uncertainty in the number of infected people\n",
    "## And at least 300 (if the number is small to not emphasize early measurments too much)\n",
    "delta_infected_new = [max(300, infected * 3) for infected in infected_new]\n",
    "\n",
    "# This assumes that there is a 10% uncertainty in the number of hospitalized people with a minimum of 50\n",
    "delta_hospitalized_new = [hospitalized * 0.15 for hospitalized in hospitalized_new]\n",
    "\n",
    "YY_larger_I = gvar(\n",
    "    [infected_new, hospitalized_new], [delta_infected_new, delta_hospitalized_new]\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run the fit\n",
    "fit_w_distancing_larger_I = nonlinear_fit(\n",
    "    data=(XX, YY_larger_I), fcn=fcn_w_distancing, prior=prior_w_distancing\n",
    ")\n",
    "\n",
    "# Summarize the fit\n",
    "summarize_fit(fit_w_distancing_larger_I)\n",
    "fig = plot_fits(fit_w_distancing_larger_I, x=chd_df.index[1:])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame(\n",
    "    data=[\n",
    "        fit_w_distancing.p,\n",
    "        fit_w_distancing_larger_I.p,\n",
    "        fit_w_distancing.p - fit_w_distancing_larger_I.p,\n",
    "    ],\n",
    "    index=[\"50% infected new uncertainty\", \"300% infected new uncertainty\", \"diff\"],\n",
    ").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, new admissions dictate the outcome of the fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictivity check: Regular SIR, with social distancing policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final question is: how far can we predict? Or alternatively, if we leave out time slices, how many do we need to consistently describe the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NT = YY.shape[0]\n",
    "\n",
    "fits = {}\n",
    "\n",
    "for nt in range(NT // 3, NT + 1):\n",
    "    yy_cut = YY[:nt].copy()\n",
    "    xx = XX.copy()\n",
    "    xx[\"n_iter\"] = nt + 1\n",
    "    fits[nt] = nonlinear_fit(\n",
    "        data=(xx, yy_cut), fcn=fcn_w_distancing, prior=prior_w_distancing\n",
    "    )\n",
    "\n",
    "fig = plot_fit_range(fits, y_max=5000, x=chd_df.index[1:], col_wrap=3)\n",
    "\n",
    "fig.show()\n",
    "DataFrame(\n",
    "    data=[fit.p for fit in fits.values()],\n",
    "    index=Series([nt * XX[\"bin_size\"] for nt in fits], name=\"fitted days\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Fits seem to be consistent once you see a \"bend\" in the new hospitalizations curve.\n",
    "E.g., after fitted days $\\geq 14$, the social distancing function parameters are affected by the fit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
